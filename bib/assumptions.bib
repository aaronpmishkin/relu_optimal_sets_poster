### Curvature Conditions ###

%% PL Condition
@InProceedings{karimi2016linear,
  author       = "Hamed Karimi and Julie Nutini and Mark Schmidt",
  editor       = "Paolo Frasconi and Niels Landwehr and Giuseppe Manco
                 and Jilles Vreeken",
  title        = "Linear Convergence of Gradient and Proximal-Gradient
                 Methods Under the Polyak-{\L}ojasiewicz Condition",
  booktitle    = "Machine Learning and Knowledge Discovery in Databases
                 - European Conference, {ECML} {PKDD} 2016",
  series       = "Lecture Notes in Computer Science",
  volume       = "9851",
  pages        = "795--811",
  publisher    = "Springer",
  year         = "2016",
}

%% invexity
@Article{ben1986invexity,
  title        = "What is invexity?",
  author       = "Adi Ben-Israel and Bertram Mond",
  journal      = "The ANZIAM Journal",
  volume       = "28",
  number       = "1",
  pages        = "1--9",
  year         = "1986",
  publisher    = "Cambridge University Press",
}

%% Restricted Secant Inequality (RSI)
@Article{zhang2013gradient,
  title        = "Gradient methods for convex minimization: {B}etter
                 rates under weaker conditions",
  author       = "Hui Zhang and Wotao Yin",
  journal      = "arXiv preprint arXiv:1303.4645",
  year         = "2013",
}

### Growth Conditions ###

%% Strong Growth + Noise
@Article{poljak1973pseudogradient,
  title        = "Pseudogradient adaptation and training algorithms",
  author       = "BT Polyak and Ya Z Tsypkin",
  journal      = "Automation and Remote Control",
  volume       = "34",
  pages        = "45--67",
  year         = "1973",
}

%% Maximal Strong Growth
@Article{tseng1998incremental,
  author       = "Paul Tseng",
  title        = "An Incremental Gradient(-Projection) Method with
                 Momentum Term and Adaptive Stepsize Rule",
  journal      = "{SIAM} Journal on Optimization",
  volume       = "8",
  number       = "2",
  pages        = "506--531",
  year         = "1998",
}

%% Maximal Strong Growth
@Article{solodov1998incremental,
  author       = "Mikhail V. Solodov",
  title        = "Incremental Gradient Algorithms with Stepsizes Bounded
                 Away from Zero",
  journal      = "Comp. Opt. and Appl.",
  volume       = "11",
  number       = "1",
  pages        = "23--35",
  year         = "1998",
}

%% Strong Growth
@Article{schmidt2013fast,
  title        = "Fast convergence of stochastic gradient descent under
                 a strong growth condition",
  author       = "Mark Schmidt and Nicolas {Le Roux}",
  journal      = "arXiv preprint arXiv:1308.6370",
  year         = "2013",
}

%% Strong Growth is necessary for linear convergence; alternative weak growth condition (SGC + noise);
%% convergence to neighbourhood for (proximal-) gradient descent under WGC + noise.
@Article{cevher2018linear,
  author       = "Volkan Cevher and Bang C{\^{o}}ng Vu",
  title        = "On the linear convergence of the stochastic gradient
                 method with constant step-size",
  journal      = "Optim. Lett.",
  volume       = "13",
  number       = "5",
  pages        = "1177--1187",
  year         = "2019",
}

%% Strong Growth + Weak Growth + Noise
@Article{khaled2020better,
  title        = "Better Theory for {SGD} in the Nonconvex World",
  author       = "Ahmed Khaled and Peter Richt{\'a}rik",
  journal      = "arXiv preprint arXiv:2002.03329",
  year         = "2020",
}
